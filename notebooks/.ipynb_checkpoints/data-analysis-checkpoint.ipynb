{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander customer satisfaction: data analysis\n",
    "\n",
    "## Some exploratory analysis and data cleaning\n",
    "\n",
    "In this notebook, we do basically two things:\n",
    "\n",
    "* **Data cleaning:** \n",
    "    * Removal of duplicated columns. \n",
    "    * One-hot encoding of categorical variables.\n",
    "* **Exploratory analysis:** \n",
    "    * Distribution of target variable. \n",
    "    * Visualization of real valued and categorical features. \n",
    "    \n",
    "## Imports and code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# starting up a console attached to this kernel\n",
    "%matplotlib inline\n",
    "%qtconsole\n",
    "import os\n",
    "\n",
    "# importing base code\n",
    "os.chdir('/home/guilherme/Documents/Kaggle/santander-satisfaction/code')\n",
    "from base import *\n",
    "\n",
    "# changing to competition dir\n",
    "os.chdir('/home/guilherme/Documents/Kaggle/santander-satisfaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows and cols:  (76020, 371)\n",
      "first rows: \n",
      "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
      "0   1     2     23                   0                        0   \n",
      "1   3     2     34                   0                        0   \n",
      "2   4     2     23                   0                        0   \n",
      "3   8     2     37                   0                      195   \n",
      "4  10     2     39                   0                        0   \n",
      "\n",
      "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
      "0                        0                        0                        0   \n",
      "1                        0                        0                        0   \n",
      "2                        0                        0                        0   \n",
      "3                      195                        0                        0   \n",
      "4                        0                        0                        0   \n",
      "\n",
      "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
      "0                        0                        0   ...     \n",
      "1                        0                        0   ...     \n",
      "2                        0                        0   ...     \n",
      "3                        0                        0   ...     \n",
      "4                        0                        0   ...     \n",
      "\n",
      "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
      "0                        0                        0                       0   \n",
      "1                        0                        0                       0   \n",
      "2                        0                        0                       0   \n",
      "3                        0                        0                       0   \n",
      "4                        0                        0                       0   \n",
      "\n",
      "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
      "0                       0                        0                        0   \n",
      "1                       0                        0                        0   \n",
      "2                       0                        0                        0   \n",
      "3                       0                        0                        0   \n",
      "4                       0                        0                        0   \n",
      "\n",
      "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
      "0                       0                       0   39205.170000       0  \n",
      "1                       0                       0   49278.030000       0  \n",
      "2                       0                       0   67333.770000       0  \n",
      "3                       0                       0   64007.970000       0  \n",
      "4                       0                       0  117310.979016       0  \n",
      "\n",
      "[5 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "# reading csv\n",
    "raw_train = pd.read_csv('data/raw/train.csv')\n",
    "raw_test = pd.read_csv('data/raw/test.csv')\n",
    "\n",
    "# saving ground-truth\n",
    "raw_train['TARGET'].to_csv('data/target.csv', index=False, header='target')\n",
    "\n",
    "# number of rows and columns \n",
    "print \"number of rows and cols: \", raw_train.shape\n",
    "\n",
    "print \"first rows: \\n\", raw_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of duplicated columns\n",
    "\n",
    "Some columns may be duplicated. Sometimes present in Kaggle competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions before (train):  (76020, 371)\n",
      "data dimensions before (test):  (75818, 370)\n",
      "data dimensions after (train):  (76020, 307)\n",
      "data dimensions after (test):  (75818, 307)\n"
     ]
    }
   ],
   "source": [
    "# removing duplicated columns\n",
    "print \"data dimensions before (train): \", raw_train.shape\n",
    "print \"data dimensions before (test): \", raw_test.shape\n",
    "\n",
    "# target variable\n",
    "y = raw_train.pop('TARGET')\n",
    "\n",
    "# removing...\n",
    "dp_rem = DuplicateRemove()\n",
    "clean_train = dp_rem.fit_transform(np.array(raw_train))\n",
    "clean_test = dp_rem.transform(np.array(raw_test))\n",
    "names = np.delete(np.array(raw_train.columns), dp_rem.remove)\n",
    "\n",
    "# printing...\n",
    "print \"data dimensions after (train): \", clean_train.shape\n",
    "print \"data dimensions after (test): \", clean_test.shape\n",
    "\n",
    "# saving new data: train\n",
    "clean_train = pd.DataFrame(clean_train, columns=names)\n",
    "clean_train.to_csv('data/no-duplicates/train.csv', index=False)\n",
    "\n",
    "# saving new data: test\n",
    "clean_test = pd.DataFrame(clean_test, columns=names)\n",
    "clean_test.to_csv('data/no-duplicates/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualization\n",
    "\n",
    "Let us see the relationship between the features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading train data\n",
    "train = pd.read_csv('data/no-duplicates/train.csv')\n",
    "target = pd.read_csv('data/target.csv')\n",
    "\n",
    "train['TARGET'] = target\n",
    "\n",
    "# importing ceil function: use on x-axis limits\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "\n",
    "# number of features shown per plot\n",
    "features_per_plot = 9\n",
    "\n",
    "# groups of features per plot\n",
    "rngs = get_plot_ranges(features_per_plot, train.shape[1])\n",
    "\n",
    "# j controls which plot we are in\n",
    "for j in range(len(rngs)):\n",
    "    # size of plot\n",
    "    plt.figure(figsize=[18,18])\n",
    "    \n",
    "    # i controls which feature we are plotting\n",
    "    for i, feat_number in enumerate(rngs[j]):\n",
    "        \n",
    "        # this should match the number of features per plot\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        \n",
    "        # feature plot parameters\n",
    "        #plt.plot(train.iloc[:, feat_number], target['TARGET'], 'kx')\n",
    "        sns.violinplot(x=\"TARGET\", y=train.columns[feat_number], data=train, inner=None)\n",
    "        plt.title('{} ({})'.format(train.columns[feat_number], feat_number), fontsize=18, weight='bold')\n",
    "    \n",
    "    # saving full plot\n",
    "    plt.savefig('vis/no-duplicates2/feat-vis-{}.png'.format(j))\n",
    "    plt.clf()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding data\n",
    "\n",
    "Saving real-valued and categorical data to different files. One-hot encoding categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading clean data\n",
    "clean_train = pd.read_csv('data/no-duplicates/train.csv')\n",
    "clean_test = pd.read_csv('data/no-duplicates/test.csv')\n",
    "\n",
    "# which columns to be converted to categorical (visual inspection)\n",
    "to_categorical = [71, 72, 73, 75, 110, 111, 118, 121, 124, 125, 126, 226, 235]\n",
    "to_categorical = clean_train.columns[to_categorical]\n",
    "\n",
    "# transform to one-hot encoding\n",
    "for col in to_categorical:\n",
    "    \n",
    "    # casting categorical columns to pandas categorical type\n",
    "    clean_train[col] = clean_train[col].astype('category')\n",
    "    clean_test[col] = clean_test[col].astype('category')\n",
    "    \n",
    "    # generating 'dummies' -> one-hot encoding\n",
    "    # using scipy CSR matrix type (sparse)\n",
    "    dummies_train = pd.get_dummies(clean_train[col], prefix=col, prefix_sep='-')\n",
    "    dummies_test = pd.get_dummies(clean_test[col], prefix=col, prefix_sep='-')\n",
    "    \n",
    "    # cleaning train and test of columns not present in both\n",
    "    intersection = list(set(dummies_train.columns) & set(dummies_test.columns))\n",
    "    dummies_train = dummies_train[intersection]\n",
    "    dummies_test = dummies_test[intersection]\n",
    "    \n",
    "    # generating separate dataset for categorical variables\n",
    "    try:\n",
    "        categorical_train = hstack([categorical_train, csr_matrix(dummies_train)])\n",
    "        categorical_test = hstack([categorical_test, csr_matrix(dummies_test)])\n",
    "    except:        \n",
    "        categorical_train = csr_matrix(dummies_train)\n",
    "        categorical_test = csr_matrix(dummies_test)\n",
    "\n",
    "# saving data without categorical columns\n",
    "no_cat_train = clean_train.drop(to_categorical, axis=1)\n",
    "no_cat_test = clean_test.drop(to_categorical, axis=1)\n",
    "no_cat_train.to_csv('data/real-valued/train.csv', index=False)\n",
    "no_cat_test.to_csv('data/real-valued/test.csv', index=False)\n",
    "\n",
    "# saving categorical data\n",
    "save_obj(categorical_train, 'data/categorical/train')\n",
    "save_obj(categorical_test, 'data/categorical/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
